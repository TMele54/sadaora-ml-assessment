{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook will leverage nursing data from CMS to draw on several insights\n",
    "\n",
    "# Nursing Burnout and its impact on Nurse Lifestyles\n",
    "# https://ldi.upenn.edu/our-work/research-updates/how-inadequate-hospital-staffing-continues-to-burn-out-nurses-and-threaten-patients/#:~:text=Before%20the%20pandemic%2C%2064.9%25%20of,to%2058.9%25%20during%20the%20pandemic.\n",
    "\n",
    "# Data Methodology\n",
    "# https://data.cms.gov/resources/payroll-based-journal-methodology-0\n",
    "\n",
    "# Data Dictionaries / Glossaries / indexes\n",
    "# https://data.cms.gov/resources/payroll-based-journal-daily-non-nurse-staffing-data-dictionary\n",
    "# https://data.cms.gov/resources/payroll-based-journal-daily-nurse-staffing-data-dictionary\n",
    "# https://www.kaggle.com/datasets/miadul/overstimulation-behavior-and-lifestyle-dataset\n",
    "# https://www.kaggle.com/datasets/manuelcamachor/level-of-anxiety-in-nursing-during-covid-pandemic\n",
    "\n",
    "# Datasets\n",
    "# https://data.cms.gov/quality-of-care/payroll-based-journal-daily-non-nurse-staffing/data\n",
    "# https://data.cms.gov/quality-of-care/payroll-based-journal-daily-nurse-staffing/data\n",
    "# https://www.kaggle.com/datasets/miadul/overstimulation-behavior-and-lifestyle-dataset\n",
    "# https://www.kaggle.com/datasets/manuelcamachor/level-of-anxiety-in-nursing-during-covid-pandemic\n",
    "\n",
    "# Hypothesis\n",
    "# Using a combination of real and synthetic data, we aspire to show that nurses who work in under-staffed medical settings, experience negative lifestyle effects by being overstimulated / having a low nurse to patient index (something like this - explore the data)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Task:\n",
    "#1. Data Familiarity & Exploration  \n",
    "# • Load and explore the dataset (can be any public dataset or one provided by you – e.g., UCI, Kaggle). \n",
    "# • Identify key trends and what the data might say about the user. \n",
    "\n",
    "#2. Build a Simple Model  \n",
    "# • Choose a modeling goal: e.g., user segmentation, outcome prediction, or recommendation. \n",
    "# • Select and justify a model (logistic regression, decision trees, simple neural net, etc.). \n",
    "# • Train and validate (simple train/test split is fine). \n",
    "\n",
    "#3. Evaluate & Explain  \n",
    "# • Use one or two performance metrics (e.g., accuracy, F1, ROC AUC). \n",
    "# • Explain the why behind your modeling choices. \n",
    "# • Summarize key insights (via comments, markdown, or a short PDF summary). \n",
    "\n",
    "#4. Final Thoughts  \n",
    "# • Briefly discuss how you’d productionize this in a startup setting."
   ],
   "id": "1d678dc9d4bce8e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:58:27.654604Z",
     "start_time": "2025-04-15T19:58:25.793891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup\n",
    "!pip install polars\n"
   ],
   "id": "880a86c4cf4520ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in c:\\users\\tmele\\anaconda3\\lib\\site-packages (1.27.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\tmele\\anaconda3\\lib\\site-packages\\mask_rcnn-2.1-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Data\n",
   "id": "7eb166f8afec20ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T20:12:17.973237Z",
     "start_time": "2025-04-15T20:12:17.454748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This Section is just for me to download the source data, the included datasets replace these files and are much smaller. There's no need to use this section other than to review how the api was accessed to download the data.\n",
    "\n",
    "# Getting the data via api\n",
    "import polars as pl\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "# define datasets for api acquisition\n",
    "non_nursing_data = [\n",
    "    {\n",
    "        \"type\": \"Non-Nursing Staffing\",\n",
    "        \"quarter\": \"Q3\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"293788f3-20a9-4ebd-ab4a-9989325ce3e7\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"Non-Nursing Staffing\",\n",
    "        \"quarter\": \"Q2\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"c06ad548-5cb2-4f29-8075-66efc2d195b6\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"Non-Nursing Staffing\",\n",
    "        \"quarter\": \"Q1\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"86603f7e-6ed8-4005-a5d3-b13d2ebcf3d4\"\n",
    "    }\n",
    "]\n",
    "non_nursing_data = [non_nursing_data[2]]\n",
    "nursing_data = [\n",
    "    {\n",
    "        \"type\": \"Nursing Staffing\",\n",
    "        \"quarter\": \"Q3\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"989fbc78-1655-487d-9f24-d68e9a0ab3af\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"Nursing Staffing\",\n",
    "        \"quarter\": \"Q2\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"dcc467d8-5792-4e5d-95be-04bf9fc930a1\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"Nursing Staffing\",\n",
    "        \"quarter\": \"Q1\",\n",
    "        \"year\": \"2024\",\n",
    "        \"id\": \"5b84bdf2-b246-4b3c-be1b-cf7c2bcb3391\"\n",
    "    }\n",
    "]\n",
    "nursing_data = [nursing_data[2]]\n",
    "\n",
    "data_sets = nursing_data #+ non_nursing_data\n",
    "\n",
    "# optional\n",
    "data_frames = []\n",
    "\n",
    "# directory of where this notebook will be run\n",
    "base_dir = os.getcwd()+\"\\\\data\\\\\"\n",
    "\n",
    "# avoid extra api calls\n",
    "for item in data_sets:\n",
    "    file = [str(val) for val in item.values()]\n",
    "    file = \"-\".join(file)+\".tsv\"\n",
    "    this_file = base_dir+file\n",
    "    \n",
    "    if os.path.exists(this_file):\n",
    "        pass # df = pl.read_csv(this_file, separator='\\t')\n",
    "        # data_frames.append(df)\n",
    "    else:\n",
    "        _id = item['id']\n",
    "        \n",
    "        # get the base url\n",
    "        api_url = \"https://data.cms.gov/data-api/v1/dataset/\"+_id+\"/data\"\n",
    "        \n",
    "        # places to store data\n",
    "        _data = []\n",
    "        \n",
    "        # get number of rows\n",
    "        response = requests.get(api_url+\"/stats\")\n",
    "        rows = response.json()\n",
    "        total_rows = rows.get(\"total_rows\")\n",
    "        i = 0 \n",
    "        \n",
    "        # api docs stated they can provide 5k per call but only 1k is in the response\n",
    "        print(f\"obtaining {total_rows} rows 1000 at a time\")\n",
    "        while i < total_rows: \n",
    "            size = 1000\n",
    "            offset_url = f\"{api_url}?/size={size}&offset={i}\"\n",
    "            offset = i\n",
    "            offset_response = requests.get(offset_url)\n",
    "            print(f\"Made request for {size} results at offset {i}\")\n",
    "            items = offset_response.json()\n",
    "            for item in items:\n",
    "                _data.append(item)\n",
    "            i = i+size\n",
    "            print([\"Size is now:\",len(_data)])\n",
    "            time.sleep(0.5)     \n",
    "            \n",
    "        df = pl.DataFrame(_data)\n",
    "        df.write_csv(this_file,include_header=True,separator=\"\\t\",line_terminator=\"\\n\",quote_char='\"',null_value=\"NA\")\n",
    "        time.sleep(120)\n"
   ],
   "id": "c1eff212235a6812",
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='data.cms.gov', port=443): Max retries exceeded with url: /data-api/v1/dataset/5b84bdf2-b246-4b3c-be1b-cf7c2bcb3391/data/stats (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000028E46867EC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    175\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dns_host, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mextra_kw\n\u001B[0;32m    176\u001B[0m     )\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m six\u001B[38;5;241m.\u001B[39mraise_from(\n\u001B[0;32m     69\u001B[0m         LocationParseError(\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, label empty or too long\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m host), \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     70\u001B[0m     )\n\u001B[1;32m---> 72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgetaddrinfo(host, port, family, socket\u001B[38;5;241m.\u001B[39mSOCK_STREAM):\n\u001B[0;32m     73\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\socket.py:976\u001B[0m, in \u001B[0;36mgetaddrinfo\u001B[1;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[0;32m    975\u001B[0m addrlist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m _socket\u001B[38;5;241m.\u001B[39mgetaddrinfo(host, port, family, \u001B[38;5;28mtype\u001B[39m, proto, flags):\n\u001B[0;32m    977\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "\u001B[1;31mgaierror\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNewConnectionError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    715\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[1;32m--> 716\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    717\u001B[0m     conn,\n\u001B[0;32m    718\u001B[0m     method,\n\u001B[0;32m    719\u001B[0m     url,\n\u001B[0;32m    720\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    721\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    722\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    723\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    724\u001B[0m )\n\u001B[0;32m    726\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:404\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_conn(conn)\n\u001B[0;32m    405\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msock\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# AppEngine might not have  `.sock`\u001B[39;00m\n\u001B[1;32m-> 1061\u001B[0m     conn\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_verified:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:363\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;66;03m# Add certificate verification\u001B[39;00m\n\u001B[1;32m--> 363\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_conn()\n\u001B[0;32m    364\u001B[0m     hostname \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:186\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NewConnectionError(\n\u001B[0;32m    187\u001B[0m         \u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to establish a new connection: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m e\n\u001B[0;32m    188\u001B[0m     )\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m conn\n",
      "\u001B[1;31mNewConnectionError\u001B[0m: <urllib3.connection.HTTPSConnection object at 0x0000028E46867EC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[0;32m    668\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    669\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    670\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[0;32m    671\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    672\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    673\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    674\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    675\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    676\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[0;32m    677\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    678\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    679\u001B[0m     )\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:802\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    800\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[1;32m--> 802\u001B[0m retries \u001B[38;5;241m=\u001B[39m retries\u001B[38;5;241m.\u001B[39mincrement(\n\u001B[0;32m    803\u001B[0m     method, url, error\u001B[38;5;241m=\u001B[39me, _pool\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, _stacktrace\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    804\u001B[0m )\n\u001B[0;32m    805\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:594\u001B[0m, in \u001B[0;36mRetry.increment\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[1;32m--> 594\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[0;32m    596\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='data.cms.gov', port=443): Max retries exceeded with url: /data-api/v1/dataset/5b84bdf2-b246-4b3c-be1b-cf7c2bcb3391/data/stats (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000028E46867EC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 80\u001B[0m\n\u001B[0;32m     77\u001B[0m _data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# get number of rows\u001B[39;00m\n\u001B[1;32m---> 80\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(api_url\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/stats\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     81\u001B[0m rows \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n\u001B[0;32m     82\u001B[0m total_rows \u001B[38;5;241m=\u001B[39m rows\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_rows\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001B[0m, in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, params\u001B[38;5;241m=\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:700\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    696\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[0;32m    697\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m    698\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m--> 700\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "\u001B[1;31mConnectionError\u001B[0m: HTTPSConnectionPool(host='data.cms.gov', port=443): Max retries exceeded with url: /data-api/v1/dataset/5b84bdf2-b246-4b3c-be1b-cf7c2bcb3391/data/stats (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000028E46867EC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:59:07.361002Z",
     "start_time": "2025-04-15T19:59:07.353902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this exists for validation as much as a way to label things and for validation. It is useful.\n",
    "data_definitions = {\n",
    "    \"PROVNUM\": \"Medicare provider number\",\n",
    "    \"PROVNAME\": \"Provider name\",\n",
    "    \"CITY\": \"Provider City\",\n",
    "    \"STATE\": \"Postal abbreviation for State\",\n",
    "    \"COUNTY_NAME\": \"Name of Provider County, unique within state\",\n",
    "    \"COUNTY_FIPS\": \"FIPS Code for Provider County, unique within state\",\n",
    "    \"CY_Qtr\": \"Calendar Quarter (yyyyQq, e.g. 2018Q4)\",\n",
    "    \"WorkDate\": \"Day for Reported Hours (yyyymmdd)\",\n",
    "    \"MDScensus\": \"Resident Census from MDS\",\n",
    "    \"Hrs_RNDON\": \"Total Hours for RN Director of Nursing\", # no EMP?\n",
    "    \"Hrs_RNDON_emp\": \"Employee Hours for RN Director of Nursing\", # this was missing and confirmed below\n",
    "    \"Hrs_RNDON_ctr\": \"Contract Hours for RN Director of Nursing\",\n",
    "    \"Hrs_RNadmin\": \"Hours for RN with administrative duties\",\n",
    "    \"Hrs_RNadmin_emp\": \"Employee Hours for RN with administrative duties\",\n",
    "    \"Hrs_RNadmin_ctr\": \"Contract Hours for RN with administrative duties\",\n",
    "    \"Hrs_RN\": \"Total Hours for RN\",\n",
    "    \"Hrs_RN_emp\": \"Employee Hours for RN\",\n",
    "    \"Hrs_RN_ctr\": \"Contract Hours for RN\",\n",
    "    \"Hrs_LPNadmin\": \"Total Hours for LPN w/ admin duties\",\n",
    "    \"Hrs_LPNadmin_emp\": \"Employee Hours for LPN w/ admin duties\",\n",
    "    \"Hrs_LPNadmin_ctr\": \"Contract Hours for LPN w/ admin duties\",\n",
    "    \"Hrs_LPN\": \"Total Hours for LPN\",\n",
    "    \"Hrs_LPN_emp\": \"Employee Hours for LPN\",\n",
    "    \"Hrs_LPN_ctr\": \"Contract Hours for LPN\",\n",
    "    \"Hrs_CNA\": \"Total Hours for CNA\",\n",
    "    \"Hrs_CNA_emp\": \"Employee Hours for CNA\",\n",
    "    \"Hrs_CNA_ctr\": \"Contract Hours for CNA\",\n",
    "    \"Hrs_NAtrn\": \"Total Hours for Nurse aide in training\",\n",
    "    \"Hrs_NAtrn_emp\": \"Employee Hours for Nurse aide in training\",\n",
    "    \"Hrs_NAtrn_ctr\": \"Contract Hours for Nurse aide in training\",\n",
    "    \"Hrs_MedAide\": \"Total Hours for Med Aide/Technician\",\n",
    "    \"Hrs_MedAide_emp\": \"Employee Hours for Med Aide/Technician\",\n",
    "    \"Hrs_MedAide_ctr\": \"Contract Hours for Med Aide/Technician\",\n",
    "    #\n",
    "    \"Hrs_Admin\": \"Total Hours for Administrator\",\n",
    "    \"Hrs_Admin_emp\": \"Employee Hours for Administrator\",\n",
    "    \"Hrs_Admin_ctr\": \"Contract Hours for Administrator\",\n",
    "    \"Hrs_Admin fn\": \"Footnote for Administrator Hours worked: 1 = Provider submitted invalid administrator hours\",\n",
    "    \"Hrs_MedDir\": \"Total Hours for Medical Director\",\n",
    "    \"Hrs_MedDir_emp\": \"Employee Hours for Medical Director\",\n",
    "    \"Hrs_MedDir_ctr\": \"Contract Hours for Medical Director\",\n",
    "    \"Hrs_OthMD\": \"Total Hours for Other Physician\",\n",
    "    \"Hrs_OthMD_emp\": \"Employee Hours for Other Physician\",\n",
    "    \"Hrs_OthMD_ctr\": \"Contract Hours for Other Physician\",\n",
    "    \"Hrs_PA\": \"Total Hours for Physician Assistant\",\n",
    "    \"Hrs_PA_emp\": \"Employee Hours for Physician Assistant\",\n",
    "    \"Hrs_PA_ctr\": \"Contract Hours for Physician Assistant\",\n",
    "    \"Hrs_NP\": \"Total Hours for Nurse Practitioner\",\n",
    "    \"Hrs_NP_emp\": \"Employee Hours for Nurse Practitioner\",\n",
    "    \"Hrs_NP_ctr\": \"Contract Hours for Nurse Practitioner\",\n",
    "    \"Hrs_ClinNrsSpec\": \"Total Hours for Clinical Nurse Specialist\",\n",
    "    \"Hrs_ClinNrsSpec_emp\": \"Employee Hours for Clinical Nurse Specialist\",\n",
    "    \"Hrs_ClinNrsSpec_ctr\": \"Contract Hours for Clinical Nurse Specialist\",\n",
    "    \"Hrs_Pharmacist\": \"Total Hours for Pharmacist\",\n",
    "    \"Hrs_Pharmacist_emp\": \"Employee Hours for Pharmacist\",\n",
    "    \"Hrs_Pharmacist_ctr\": \"Contract Hours for Pharmacist\",\n",
    "    \"Hrs_Dietician\": \"Total Hours for Dietician\",\n",
    "    \"Hrs_Dietician_emp\": \"Employee Hours for Dietician\",\n",
    "    \"Hrs_Dietician_ctr\": \"Contract Hours for Dietician\",\n",
    "    \"Hrs_FeedAsst\": \"Total Hours for Feeding Assistant\",\n",
    "    \"Hrs_FeedAsst_emp\": \"Employee Hours for Feeding Assistant\",\n",
    "    \"Hrs_FeedAsst_ctr\": \"Contract Hours for Feeding Assistant\",\n",
    "    \"Hrs_OT\": \"Total Hours for Occupational Therapist\",\n",
    "    \"Hrs_OT_emp\": \"Employee Hours for Occupational Therapist\",\n",
    "    \"Hrs_OT_ctr\": \"Contract Hours for Occupational Therapist\",\n",
    "    \"Hrs_OTasst\": \"Total Hours for Occupational Therapy Assistant\",\n",
    "    \"Hrs_OTasst_emp\": \"Employee Hours for Occupational Therapy Assistant\",\n",
    "    \"Hrs_OTasst_ctr\": \"Contract Hours for Occupational Therapy Assistant\",\n",
    "    \"Hrs_OTaide\": \"Total Hours for Occupational Therapy Aide\",\n",
    "    \"Hrs_OTaide_emp\": \"Employee Hours for Occupational Therapy Aide\",\n",
    "    \"Hrs_OTaide_ctr\": \"Contract Hours for Occupational Therapy Aide\",\n",
    "    \"Hrs_PT\": \"Total Hours for Physical Therapist\",\n",
    "    \"Hrs_PT_emp\": \"Employee Hours for Physical Therapist\",\n",
    "    \"Hrs_PT_ctr\": \"Contract Hours for Physical Therapist\",\n",
    "    \"Hrs_PTasst\": \"Total Hours for Physical Therapy Assistant\",\n",
    "    \"Hrs_PTasst_emp\": \"Employee Hours for Physical Therapy Assistant\",\n",
    "    \"Hrs_PTasst_ctr\": \"Contract Hours for Physical Therapy Assistant\",\n",
    "    \"Hrs_PTaide\": \"Total Hours for Physical Therapy Aide\",\n",
    "    \"Hrs_PTaide_emp\": \"Employee Hours for Physical Therapy Aide\",\n",
    "    \"Hrs_PTaide_ctr\": \"Contract Hours for Physical Therapy Aide\",\n",
    "    \"Hrs_RespTher\": \"Total Hours for Respiratory Therapist\",\n",
    "    \"Hrs_RespTher_emp\": \"Employee Hours for Respiratory Therapist\",\n",
    "    \"Hrs_RespTher_ctr\": \"Contract Hours for Respiratory Therapist\",\n",
    "    \"Hrs_RespTech\": \"Total Hours for Respiratory Therapy Technician\",\n",
    "    \"Hrs_RespTech_emp\": \"Employee Hours for Respiratory Therapy Technician\",\n",
    "    \"Hrs_RespTech_ctr\": \"Contract Hours for Respiratory Therapy Technician\",\n",
    "    \"Hrs_SpcLangPath\": \"Total Hours for Speech/Language Pathologist\",\n",
    "    \"Hrs_SpcLangPath_emp\": \"Employee Hours for Speech/Language Pathologist\",\n",
    "    \"Hrs_SpcLangPath_ctr\": \"Contract Hours for Speech/Language Pathologist\",\n",
    "    \"Hrs_TherRecSpec\": \"Total Hours for Therapeutic Recreation Specialist\",\n",
    "    \"Hrs_TherRecSpec_emp\": \"Employee Hours for Therapeutic Recreation Specialist\",\n",
    "    \"Hrs_TherRecSpec_ctr\": \"Contract Hours for Therapeutic Recreation Specialist\",\n",
    "    \"Hrs_QualActvProf\": \"Total Hours for Qualified Activities Professional\",\n",
    "    \"Hrs_QualActvProf_emp\": \"Employee Hours for Qualified Activities Professional\",\n",
    "    \"Hrs_QualActvProf_ctr\": \"Contract Hours for Qualified Activities Professional\",\n",
    "    \"Hrs_OthActv\": \"Total Hours for Other Activities Staff\",\n",
    "    \"Hrs_OthActv_emp\": \"Employee Hours for Other Activities Staff\",\n",
    "    \"Hrs_OthActv_ctr\": \"Contract Hours for Other Activities Staff\",\n",
    "    \"Hrs_QualSocWrk\": \"Total Hours for Qualified Social Worker\",\n",
    "    \"Hrs_QualSocWrk_emp\": \"Employee Hours for Qualified Social Worker\",\n",
    "    \"Hrs_QualSocWrk_ctr\": \"Contract Hours for Qualified Social Worker\",\n",
    "    \"Hrs_OthSocWrk\": \"Total Hours for Other Social Worker\",\n",
    "    \"Hrs_OthSocWrk_emp\": \"Employee Hours for Other Social Worker\",\n",
    "    \"Hrs_OthSocWrk_ctr\": \"Contract Hours for Other Social Worker\",\n",
    "    \"Hrs_MHSvc\": \"Total Hours for Mental Health Service Worker\",\n",
    "    \"Hrs_MHSvc_emp\": \"Employee Hours for Mental Health Service Worker\",\n",
    "    \"Hrs_MHSvc_ctr\": \"Contract Hours for Mental Health Service Worker\"\n",
    "}   "
   ],
   "id": "a3d2be0461e1d7aa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T21:49:18.087110Z",
     "start_time": "2025-04-15T21:49:17.085619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transform Data into smaller usable components for analysis\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#pl.Config.set_tbl_width_chars(100)\n",
    "#pl.Config.set_fmt_str_lengths(100)\n",
    "\n",
    "# directory of where this notebook will be run\n",
    "base_dir = os.getcwd()+\"\\\\data\\\\\"\n",
    "\n",
    "nurses = pl.read_csv(base_dir+\"Nursing Staffing-Q1-2024-5b84bdf2-b246-4b3c-be1b-cf7c2bcb3391.tsv\", separator=\"\\t\", infer_schema_length=10000,ignore_errors=True)\n",
    "non_nurses = pl.read_csv(base_dir+\"Non-Nursing Staffing-Q2-2024-86603f7e-6ed8-4005-a5d3-b13d2ebcf3d4.tsv\", separator=\"\\t\", infer_schema_length=10000,ignore_errors=True)\n",
    "provider_info = pl.read_csv(base_dir+\"Provider_Info.csv\")\n",
    "\n",
    "\n",
    "################################################## Inspect/Prepare Data ##################################################\n",
    "################################################## Inspect/Prepare Data ##################################################\n",
    "\n",
    "# let's work with good samples\n",
    "nurses = nurses.filter(pl.col(\"PROVNUM\").is_not_null())\n",
    "non_nurses = non_nurses.filter(pl.col(\"PROVNUM\").is_not_null())\n",
    "\n",
    "# I noticed the WorkDate and date processed col is not a date, string with date\n",
    "# strings\n",
    "nurses = nurses.with_columns(pl.col(\"WorkDate\").cast(pl.Utf8).alias(\"WorkDate\"))\n",
    "non_nurses = non_nurses.with_columns(pl.col(\"WorkDate\").cast(pl.Utf8).alias(\"WorkDate\"))\n",
    "# date\n",
    "nurses = nurses.with_columns(pl.col(\"WorkDate\").str.strptime(pl.Date, \"%Y%m%d\").alias(\"WorkDate\"))\n",
    "non_nurses = non_nurses.with_columns(pl.col(\"WorkDate\").str.strptime(pl.Date, \"%Y%m%d\").alias(\"WorkDate\"))\n",
    "provider_info = provider_info.with_columns(pl.col(\"Processing Date\").str.strptime(pl.Date, \"%m/%d/%Y\").alias(\"Processing Date\"))\n",
    "\n",
    "# the max provnum is for prov 335232, the data dict does not explicitly state the emp and ctr fields add to total\n",
    "# this could be assumed but, check first to ensure understanding is clear. these three expression yield this is true\n",
    "# and our thinking was correct. Every role in the data follows this format so that clears up basically all the fields\n",
    "_nurses = nurses.group_by(\"PROVNUM\").agg(pl.sum('Hrs_RN').alias('Registered Nurses')).sort('Registered Nurses', descending=True)\n",
    "print(\"Total Hours:\",_nurses[0][\"Registered Nurses\"][0])\n",
    "\n",
    "__nurses = nurses.group_by(\"PROVNUM\").agg(pl.sum('Hrs_RN_emp').alias('Registered Nurses emp')).filter(pl.col('PROVNUM') == 335232)\n",
    "print(\"Employee Hours:\",__nurses[0][\"Registered Nurses emp\"][0])\n",
    "\n",
    "___nurses = nurses.group_by(\"PROVNUM\").agg(pl.sum('Hrs_RN_ctr').alias('Registered Nurses ctr')).filter(pl.col('PROVNUM') == 335232)\n",
    "print(\"Contract Hours:\",___nurses[0][\"Registered Nurses ctr\"][0])\n",
    "\n",
    "# is the difference really small because of rounding only\n",
    "if _nurses[0][\"Registered Nurses\"][0] - __nurses[0][\"Registered Nurses emp\"][0] - ___nurses[0][\"Registered Nurses ctr\"][0] < 1:\n",
    "    print(\"Employee and contract hours equal total hours\")\n",
    "else:\n",
    "    print(False)\n",
    "\n",
    "# this field from non nurses is different   \n",
    "#    \"Hrs_Admin fn\": \"Footnote for Administrator Hours worked: 1 = Provider submitted invalid administrator hours\",\n",
    "# what do they mean by this, inspect \n",
    "_non_nurses = non_nurses.filter(pl.col(\"Hrs_Admin_fn\") != \"1\")['Hrs_Admin_fn']\n",
    "no_mistake = len(_non_nurses)\n",
    "_non_nurses = non_nurses.filter(pl.col(\"Hrs_Admin_fn\") == \"1\")['Hrs_Admin_fn']\n",
    "mistake = len(_non_nurses)\n",
    "\n",
    "print(\"the % of mistakes in the Admin field is:\", mistake/no_mistake*100) # <1% is basically irrelevant, but could have been\n",
    "\n",
    "# I don't see a \"Hrs_RNDON_emp\" in my data dictionary above - lets check if I missed copying it or if it is not there\n",
    "if \"Hrs_RNDON_emp\" in nurses.columns:\n",
    "    print(\"Hrs_RNDON_emp is in nurses\")\n",
    "# it is in the columns, I made a copy/paste error in making my data dict - I will add it back and note it\n"
   ],
   "id": "7c445f60d2d90181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hours: 45625.189999999995\n",
      "Employee Hours: 35137.75000000001\n",
      "Contract Hours: 10487.44\n",
      "Employee and contract hours equal total hours\n",
      "the % of mistakes in the Admin field is: 0.6361856823266219\n",
      "Hrs_RNDON_emp is in nurses\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4ab7a513ef0e2421"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T21:50:12.735323Z",
     "start_time": "2025-04-15T21:50:12.279123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################## Data Insights ##################################################\n",
    "################################################## Data Insights ##################################################\n",
    "\n",
    "##################################################     Story     ##################################################\n",
    "# Basically I am thinking that information about a provider (`Provider Info`.csv) is predictive in whether or \n",
    "# not a nursing home would use contract vs employee workers. For a traveling nurse, knowing just these few variables\n",
    "# would help them understand if they will be able to work and live in that city/place, impacting their lifestyle.\n",
    "# fuck idk, i dont love it, ill try it i guess\n",
    "##################################################     Story     ##################################################\n",
    "\n",
    "show=False\n",
    "def total_hours():\n",
    "    # make two collections of workers, one for nurses one for non nurses\n",
    "    _nurse_workers = []\n",
    "    _non_nurse_workers = []\n",
    "    \n",
    "    f=0# this flag flips when I stop seeing unique worker fields from nurses dataset\n",
    "    for k,v in data_definitions.items():\n",
    "        if f == 0:\n",
    "            if 'Hrs' in k and 'emp' not in k and 'ctr' not in k and 'fn' not in k and \"DON\" not in k and \"admin\" not in k:\n",
    "                _nurse_workers.append(k)\n",
    "        else:\n",
    "            if 'Hrs' in k and 'emp' not in k and 'ctr' not in k and 'fn' not in k:\n",
    "                _non_nurse_workers.append(k)\n",
    "        if 'MedAide' in k and 'ctr' in k:\n",
    "            f=1\n",
    "    return _nurse_workers, _non_nurse_workers\n",
    "\n",
    "def employee_hours():\n",
    "    # make two collections of workers, one for nurses one for non nurses\n",
    "    _nurse_workers = []\n",
    "    _non_nurse_workers = []\n",
    "    \n",
    "    f=0# this flag flips when I stop seeing unique worker fields from nurses dataset\n",
    "    for k,v in data_definitions.items():\n",
    "        if f == 0:\n",
    "            if 'Hrs' in k and 'emp' in k and 'ctr' not in k and 'fn' not in k and \"DON\" not in k and \"admin\" not in k:\n",
    "                _nurse_workers.append(k)\n",
    "        else:\n",
    "            if 'Hrs' in k and 'emp' in k and 'ctr' not in k and 'fn' not in k:\n",
    "                _non_nurse_workers.append(k)\n",
    "        if 'MedAide' in k and 'ctr' in k:\n",
    "            f=1\n",
    "    return _nurse_workers, _non_nurse_workers\n",
    "\n",
    "def contract_hours():\n",
    "    # make two collections of workers, one for nurses one for non nurses\n",
    "    _nurse_workers = []\n",
    "    _non_nurse_workers = []\n",
    "    \n",
    "    f=0# this flag flips when I stop seeing unique worker fields from nurses dataset\n",
    "    for k,v in data_definitions.items():\n",
    "        if f == 0:\n",
    "            if 'Hrs' in k and 'emp' not in k and 'ctr' in k and 'fn' not in k and \"DON\" not in k and \"admin\" not in k:\n",
    "                _nurse_workers.append(k)\n",
    "        else:\n",
    "            if 'Hrs' in k and 'emp' not in k and 'ctr' in k and 'fn' not in k:\n",
    "                _non_nurse_workers.append(k)\n",
    "        if 'MedAide' in k and 'ctr' in k:\n",
    "            f=1\n",
    "    return _nurse_workers, _non_nurse_workers\n",
    "\n",
    "# fields\n",
    "tot_n, tot_nn = total_hours()\n",
    "emp_n, emp_nn = employee_hours()\n",
    "ctr_n, ctr_nn = contract_hours()\n",
    "\n",
    "print(tot_n)\n",
    "print(emp_n)\n",
    "print(ctr_n)\n",
    "\n",
    "# scrapping the non-nurse angleal\n",
    "\n",
    "X = 15000000\n",
    "\n",
    "# Total work of nurses\n",
    "total_work = nurses.group_by(\"PROVNAME\").agg(pl.mean(tot_n)).with_columns(total_work=pl.sum_horizontal(tot_n)).sort('total_work', descending=True)\n",
    "#print(total_work.head())\n",
    "\n",
    "# top X facilities with the highest total nursing hours\n",
    "top_X_n = list(nurses.group_by(\"PROVNAME\").agg(pl.mean(tot_n)).with_columns(total_work=pl.sum_horizontal(tot_n)).sort('total_work', descending=True).head(X)[\"PROVNAME\"])\n",
    "\n",
    "#print(\"top X facilities with the highest total nursing hours\")\n",
    "#print(top_X_n)\n",
    "\n",
    "# of those ten, what is the % of employee to contract workers\n",
    "# employee & contract\n",
    "top_X_nurses = nurses.filter(pl.col(\"PROVNAME\").is_in(top_X_n))\n",
    "\n",
    "top_X_emp_ctr = top_X_nurses.with_columns(\n",
    "    (pl.col(emp_n[0]) / pl.col(tot_n[0]) * 100).round(2).alias('%emp'+emp_n[0]).fill_nan(None),\n",
    "    (pl.col(emp_n[1]) / pl.col(tot_n[1]) * 100).round(2).alias('%emp'+emp_n[1]).fill_nan(None),\n",
    "    (pl.col(emp_n[2]) / pl.col(tot_n[2]) * 100).round(2).alias('%emp'+emp_n[2]).fill_nan(None),\n",
    "    (pl.col(emp_n[3]) / pl.col(tot_n[3]) * 100).round(2).alias('%emp'+emp_n[3]).fill_nan(None),\n",
    "    (pl.col(emp_n[4]) / pl.col(tot_n[4]) * 100).round(2).alias('%emp'+emp_n[4]).fill_nan(None),\n",
    "    (pl.col(ctr_n[0]) / pl.col(tot_n[0]) * 100).round(2).alias('%ctr'+ctr_n[0]).fill_nan(None),\n",
    "    (pl.col(ctr_n[1]) / pl.col(tot_n[1]) * 100).round(2).alias('%ctr'+ctr_n[1]).fill_nan(None),\n",
    "    (pl.col(ctr_n[2]) / pl.col(tot_n[2]) * 100).round(2).alias('%ctr'+ctr_n[2]).fill_nan(None),\n",
    "    (pl.col(ctr_n[3]) / pl.col(tot_n[3]) * 100).round(2).alias('%ctr'+ctr_n[3]).fill_nan(None),\n",
    "    (pl.col(ctr_n[4]) / pl.col(tot_n[4]) * 100).round(2).alias('%ctr'+ctr_n[4]).fill_nan(None),\n",
    ").select(\n",
    "    [\"PROVNAME\"]+\n",
    "    [\"%emp\"+val for val in emp_n]+\n",
    "    [\"%ctr\"+val for val in ctr_n]\n",
    ").group_by(\"PROVNAME\").agg(pl.mean([\"%emp\"+val for val in emp_n]+[\"%ctr\"+val for val in ctr_n]))\n",
    "\n",
    "# fix visual showing percentage of work done by contract and employee nurses\n",
    "#fig = px.bar(top_X_emp_ctr.to_pandas(), x='PROVNAME', y=[\"%emp\"+val for val in emp_n]+[\"%ctr\"+val for val in ctr_n], color='PROVNAME', barmode='group', title='Fruit Sales in 2020 and 2021')\n",
    "#fig.show()\n",
    "\n",
    "\n",
    "# For all facilities what is the distribution of contract work %\n",
    "total_work_ctr = top_X_emp_ctr.group_by(\"PROVNAME\").agg(pl.mean([\"%ctr\"+val for val in ctr_n])).with_columns(total_work=pl.mean_horizontal([\"%ctr\"+val for val in ctr_n])).sort('total_work', descending=True)\n",
    "\n",
    "total_work_ctr_hist = pl.DataFrame({\"hist_all\": pl.concat(total_work_ctr[[\"%ctr\"+val for val in ctr_n]])})\n",
    "\n",
    "if show:\n",
    "    sns.histplot(total_work_ctr_hist[\"hist_all\"], bins=100, kde=True, color=\"blue\", edgecolor=\"black\", linewidth=1.5)\n",
    "    plt.xlabel(\"Contracted Registered Nurse %Mean Hours\")\n",
    "    plt.title(\"Histogram of Contracted Registered Nurse %Mean Hours\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=total_work_ctr[\"%ctrHrs_RN_ctr\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_ctr[\"%ctrHrs_LPN_ctr\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_ctr[\"%ctrHrs_CNA_ctr\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_ctr[\"%ctrHrs_NAtrn_ctr\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_ctr[\"%ctrHrs_MedAide_ctr\"]))\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "# For all facilities what is the distribution of Employee work %\n",
    "total_work_emp = top_X_emp_ctr.group_by(\"PROVNAME\").agg(pl.mean([\"%emp\"+val for val in emp_n])).with_columns(total_work=pl.mean_horizontal([\"%emp\"+val for val in emp_n])).sort('total_work', descending=True)\n",
    "\n",
    "total_work_emp_hist = pl.DataFrame({\"hist_all\": pl.concat(total_work_emp[[\"%emp\"+val for val in emp_n]])})\n",
    "\n",
    "if show:\n",
    "    sns.histplot(total_work_emp_hist[\"hist_all\"], bins=10, kde=True, color=\"blue\", edgecolor=\"black\", linewidth=1.5)\n",
    "    plt.xlabel(\"Employee Registered Nurse %Mean Hours\")\n",
    "    plt.title(\"Histogram of Employee Registered Nurse %Mean Hours\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=total_work_emp[\"%empHrs_RN_emp\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_emp[\"%empHrs_LPN_emp\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_emp[\"%empHrs_CNA_emp\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_emp[\"%empHrs_NAtrn_emp\"]))\n",
    "    fig.add_trace(go.Histogram(x=total_work_emp[\"%empHrs_MedAide_emp\"]))\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.show()\n",
    "\n",
    "# For a provider if more than 50% of their total work comes from contract then they are label contract\n",
    "# if more then 50% come from employee then they are label employee\n",
    "\n",
    "# Using the total number of worked hours for the 5 main nursing classes, if the majority of the\n",
    "# work was completed by employees, it is an employer type, else it is a contractor type\n",
    "\n",
    "labeled_facilities = nurses.group_by(\"PROVNUM\").agg(\n",
    "    [\n",
    "        pl.mean(tot_n),\n",
    "        pl.mean(emp_n),\n",
    "        pl.mean(ctr_n),\n",
    "    ]\n",
    ").with_columns(\n",
    "    total_work=pl.sum_horizontal(tot_n),\n",
    "    emp_work=pl.sum_horizontal(emp_n),\n",
    "    ctr_work=pl.sum_horizontal(ctr_n)\n",
    ").sort(\n",
    "    'total_work', \n",
    "    descending=True\n",
    ")\n",
    "\n",
    "labeled_facilities = labeled_facilities.with_columns(\n",
    "    pl.when(pl.col(\"ctr_work\") >= pl.col(\"emp_work\")).then(pl.lit(\"Contractor\")).otherwise(pl.lit(\"Employer\")).alias(\"ML_Label\")\n",
    ")\n",
    "\n",
    "labeled_facilities = labeled_facilities.with_columns(\n",
    "    pl.col(\"PROVNUM\").cast(pl.Utf8).alias(\"PROVNUM\")\n",
    ")\n",
    "\n",
    "#pin = provider_info.with_columns(\n",
    "#    pl.col(\"PROVNUM\").cast(pl.String).alias(\"PROVNUM\")\n",
    "#)\n",
    "\n",
    "labeled_facilities = labeled_facilities.rename({\"PROVNUM\": \"Federal Provider Number\"})\n",
    "labeled_facilities = labeled_facilities[\"Federal Provider Number\", \"ML_Label\"]\n",
    "\n",
    "print(labeled_facilities[\"Federal Provider Number\"])\n",
    "print(provider_info[\"Federal Provider Number\"])\n",
    "print(labeled_facilities.columns)\n",
    "print(provider_info.columns)\n",
    "out = provider_info.join(labeled_facilities, on=\"Federal Provider Number\", how=\"left\")\n",
    "\n",
    "# Save to CSV with custom separator\n",
    "print(\"SAVING TO CSV\")\n",
    "out.write_csv(\"data/output.csv\", separator='\\t')\n",
    "print(\"SAVED TO CSV\")\n",
    "\n",
    "\"\"\"\n",
    "#non_nurses = non_nurses.with_columns(pl.col([val for val in tot_nn]).cast(pl.i64).alias([val for val in tot_nn]))\n",
    "\n",
    "non_labeled_facilities = non_nurses.group_by(\"PROVNUM\").agg(\n",
    "    [\n",
    "        pl.mean(tot_nn),\n",
    "        pl.mean(emp_nn),\n",
    "        pl.mean(ctr_nn),\n",
    "    ]\n",
    ")[tot_nn+emp_nn+ctr_nn]\n",
    "\n",
    "non_nurses = non_nurses.with_columns(\n",
    "    pl.col(\"Hrs_Admin\").cast(pl.Float64).alias(\"Hrs_Admin\")\n",
    ")\n",
    "\n",
    "print(\"SJSSJSJS\" *100)\n",
    "print(non_labeled_facilities.columns)\n",
    "print(non_labeled_facilities.dtypes)\n",
    ".with_columns(\n",
    "    total_work=pl.sum_horizontal(tot_nn),\n",
    "    emp_work=pl.sum_horizontal(emp_nn),\n",
    "    ctr_work=pl.sum_horizontal(ctr_nn)\n",
    ").sort(\n",
    "    'total_work', \n",
    "    descending=True\n",
    "))\n",
    "print(non_labeled_facilities)\n",
    "\n",
    "non_labeled_facilities = non_labeled_facilities.with_columns(\n",
    "    pl.when(pl.col(\"ctr_work\") >= pl.col(\"emp_work\")).then(pl.lit(\"Contractor\")).otherwise(pl.lit(\"Employer\")).alias(\"ML_Label\")\n",
    ")\n",
    "\n",
    "print(non_labeled_facilities)\n",
    "\n",
    "show=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example histogram\n",
    "if show:\n",
    "    sns.histplot(nurses[\"Hrs_RN\"], bins=100, kde=True, color=\"blue\", edgecolor=\"black\", linewidth=1.5)\n",
    "    plt.xlabel(\"Registered Nurse % hours\")\n",
    "    plt.title(\"Histogram of Registered Nurse % hours\")\n",
    "    plt.show()\n",
    "\n",
    "working_nurses = nurses.filter(pl.col(\"Hrs_RN\") > 0)\n",
    "working_nurses = working_nurses.group_by(\"WorkDate\").agg(pl.mean('Hrs_RN').alias('RNs')).sort('WorkDate', descending=True)\n",
    "fig = px.line(working_nurses.to_pandas(), x=\"WorkDate\", y=\"RNs\", title=\"Rn Hrs by Date\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "# I see a cycle, wow, weekends, they average 450k hrs during the weekend, but only 525 (75k more) during the week\n",
    "# I also notice it is a little shorter just after new years\n",
    "# Let's compare them to non nurses, how about pharmasists\n",
    "\n",
    "working_non_nurses = non_nurses.filter(pl.col(\"Hrs_Pharmacist\") > 0)\n",
    "working_non_nurses = working_non_nurses.group_by(\"WorkDate\").agg(pl.mean('Hrs_Pharmacist').alias('PMs')).sort('WorkDate', descending=True)\n",
    "\n",
    "fig = px.line(working_non_nurses.to_pandas(), x=\"WorkDate\", y=\"PMs\", title=\"PM Hrs by Date\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "# so nurses work 525k to pharmacists 8k... and 450k to 1.5k\n",
    "# physicians assistants must do more\n",
    "working_non_nurses = non_nurses.filter(pl.col(\"Hrs_PA\") > 0)\n",
    "working_non_nurses = working_non_nurses.group_by(\"WorkDate\").agg(pl.mean('Hrs_PA').alias('PAs')).sort('WorkDate', descending=True)\n",
    "\n",
    "fig = px.line(working_non_nurses.to_pandas(), x=\"WorkDate\", y=\"PAs\", title=\"PA Hrs by Date\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "# or not...\n",
    "# let's compare registered nurses to those with director or admin roles\n",
    "\n",
    "rn = nurses.filter(pl.col(\"Hrs_RN\") > 0)\n",
    "rn = rn.group_by(\"WorkDate\").agg(pl.mean('Hrs_RN').alias('RNs')).sort('WorkDate', descending=True)\n",
    "\n",
    "rnd = nurses.filter(pl.col(\"Hrs_RNDON\") > 0)\n",
    "rnd = rnd.group_by(\"WorkDate\").agg(pl.mean('Hrs_RNDON').alias('RNDirs')).sort('WorkDate', descending=True)\n",
    "\n",
    "rna = nurses.filter(pl.col(\"Hrs_RNadmin\") > 0)\n",
    "rna = rna.group_by(\"WorkDate\").agg(pl.mean('Hrs_RNadmin').alias('RNA')).sort('WorkDate', descending=True)\n",
    "\n",
    "rnj = rn.join(rnd, on=\"WorkDate\", how=\"left\").join(rna, on=\"WorkDate\", how=\"left\")\n",
    "\n",
    "fig = px.line(rnj.to_pandas(), x=\"WorkDate\", y=[\"RNs\", \"RNDirs\", \"RNA\"], title=\"RN x RNDirs x RNA Hrs by Date\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "# make two sep collection of total hours, one for nurses one for non nurses\n",
    "_nurse_workers = []\n",
    "_non_nurse_workers = []\n",
    "f=0# this flag flips when i stop seeing unique worker fields from nurses dataset\n",
    "for k,v in data_definitions.items():\n",
    "    if f == 0:\n",
    "        if 'Hrs' in k and 'emp' not in k and 'ctr' not in k and 'fn' not in k and \"DON\" not in k and \"admin\" not in k:\n",
    "            _nurse_workers.append(k)\n",
    "    else:\n",
    "        if 'Hrs' in k and 'emp' not in k and 'ctr' not in k and 'fn' not in k:\n",
    "            _non_nurse_workers.append(k)\n",
    "    if 'MedAide' in k:\n",
    "        f=1\n",
    "\n",
    "# these seem to be null, check again, DEL\n",
    "_non_nurse_workers.remove('Hrs_Admin')\n",
    "\n",
    "# top_nurse_workers = nurses.group_by(\"PROVNAME\").agg(pl.sum(_nurse_workers)).sort('PROVNAME', descending=True)\n",
    "# print(top_nurse_workers)\n",
    "\n",
    "_nurses = nurses.group_by(\"WorkDate\").agg(pl.mean(_nurse_workers)).sort('WorkDate', descending=True)\n",
    "_non_nurses = non_nurses.group_by(\"WorkDate\").agg(pl.mean(_non_nurse_workers)).sort('WorkDate', descending=True)\n",
    "\n",
    "fig = px.line(_nurses.to_pandas(), x=\"WorkDate\", y=_nurse_workers, title=\"Nurses\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "fig = px.line(_non_nurses.to_pandas(), x=\"WorkDate\", y=_non_nurse_workers, title=\"Non-Nurses\")\n",
    "if show:\n",
    "    fig.show()\n",
    "\n",
    "# For the set of all places, do places with more support staff have lower nurse working hours\n",
    "# Quick test\n",
    "# top ten places with the most nurse hours and non nurse hours\n",
    "top_10_n = nurses.group_by(\"PROVNAME\").agg(pl.mean(_nurse_workers)).with_columns(total_work=pl.sum_horizontal(_nurse_workers)).sort('total_work', descending=True).head(10)#[\"PROVNAME\"])\n",
    "top_10_nn = non_nurses.group_by(\"PROVNAME\").agg(pl.mean(_non_nurse_workers)).with_columns(total_work=pl.sum_horizontal(_non_nurse_workers)).sort('total_work', descending=True).head(10)#[\"PROVNAME\"])\n",
    "\n",
    "common = list(set(top_10_n) & set(top_10_nn))\n",
    "\n",
    "#_top_hours_nurses = nurses.group_by(\"PROVNUM\").agg(pl.sum('Hrs_RN').alias('Registered Nurses')).sort('Registered Nurses', descending=True)\n",
    "\n",
    "#top_provnums = list(_top_hours_nurses[0:10][\"PROVNUM\"])\n",
    "#top_prov = nurses.filter(pl.col(\"PROVNUM\").is_in(top_provnums))\n",
    "#fig = px.box(top_prov, y=_top_hours_nurses, x=\"PROVNAME\", points=\"all\", notched=True, title=\"Box plot\")\n",
    "#fig.show()\n",
    "#_top_hours_non_nurses = non_nurses.group_by(\"PROVNUM\").agg(pl.sum('Hrs_RN').alias('Registered Nurses')).sort('Registered Nurses', descending=True)\n",
    "# There are lots and lots of insights in the data\n",
    "\"\"\""
   ],
   "id": "e4c6acfa333c7080",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hrs_RN', 'Hrs_LPN', 'Hrs_CNA', 'Hrs_NAtrn', 'Hrs_MedAide']\n",
      "['Hrs_RN_emp', 'Hrs_LPN_emp', 'Hrs_CNA_emp', 'Hrs_NAtrn_emp', 'Hrs_MedAide_emp']\n",
      "['Hrs_RN_ctr', 'Hrs_LPN_ctr', 'Hrs_CNA_ctr', 'Hrs_NAtrn_ctr', 'Hrs_MedAide_ctr']\n",
      "shape: (14_395,)\n",
      "Series: 'Federal Provider Number' [str]\n",
      "[\n",
      "\t\"335100\"\n",
      "\t\"335644\"\n",
      "\t\"335063\"\n",
      "\t\"335462\"\n",
      "\t\"335555\"\n",
      "\t…\n",
      "\t\"235523\"\n",
      "\t\"285243\"\n",
      "\t\"345542\"\n",
      "\t\"45401\"\n",
      "\t\"315471\"\n",
      "]\n",
      "shape: (15_640,)\n",
      "Series: 'Federal Provider Number' [str]\n",
      "[\n",
      "\t\"015019\"\n",
      "\t\"015113\"\n",
      "\t\"015112\"\n",
      "\t\"015114\"\n",
      "\t\"015123\"\n",
      "\t…\n",
      "\t\"676372\"\n",
      "\t\"676367\"\n",
      "\t\"676391\"\n",
      "\t\"676377\"\n",
      "\t\"676382\"\n",
      "]\n",
      "['Federal Provider Number', 'ML_Label']\n",
      "['index', 'Federal Provider Number', 'Provider Name', 'Provider Address', 'Provider City', 'Provider State', 'Provider Zip Code', 'Provider Phone Number', 'Provider SSA County Code', 'Provider County Name', 'Ownership Type', 'Number of Certified Beds', 'Number of Residents in Certified Beds', 'Provider Type', 'Provider Resides in Hospital', 'Legal Business Name', 'Date First Approved to Provide Medicare and Medicaid services', 'Continuing Care Retirement Community', 'Special Focus Facility', 'Most Recent Health Inspection More Than 2 Years Ago', 'Provider Changed Ownership in Last 12 Months', 'With a Resident and Family Council', 'Automatic Sprinkler Systems in All Required Areas', 'Overall Rating', 'Overall Rating Footnote', 'Health Inspection Rating', 'Health Inspection Rating Footnote', 'QM Rating', 'QM Rating Footnote', 'Staffing Rating', 'Staffing Rating Footnote', 'RN Staffing Rating', 'RN Staffing Rating Footnote', 'Reported Staffing Footnote', 'Physical Therapist Staffing Footnote', 'Reported CNA Staffing Hours per Resident per Day', 'Reported LPN Staffing Hours per Resident per Day', 'Reported RN Staffing Hours per Resident per Day', 'Reported Licensed Staffing Hours per Resident per Day', 'Reported Total Nurse Staffing Hours per Resident per Day', 'Reported Physical Therapist Staffing Hours per Resident Per Day', 'Expected CNA Staffing Hours per Resident per Day', 'Expected LPN Staffing Hours per Resident per Day', 'Expected RN Staffing Hours per Resident per Day', 'Expected Total Nurse Staffing Hours per Resident per Day', 'Adjusted CNA Staffing Hours per Resident per Day', 'Adjusted LPN Staffing Hours per Resident per Day', 'Adjusted RN Staffing Hours per Resident per Day', 'Adjusted Total Nurse Staffing Hours per Resident per Day', 'Cycle 1 Total Number of Health Deficiencies', 'Cycle 1 Number of Standard Health Deficiencies', 'Cycle 1 Number of Complaint Health Deficiencies', 'Cycle 1 Health Deficiency Score', 'Cycle 1 Standard Survey Health Date', 'Cycle 1 Number of Health Revisits', 'Cycle 1 Health Revisit Score', 'Cycle 1 Total Health Score', 'Cycle 2 Total Number of Health Deficiencies', 'Cycle 2 Number of Standard Health Deficiencies', 'Cycle 2 Number of Complaint Health Deficiencies', 'Cycle 2 Health Deficiency Score', 'Cycle 2 Standard Health Survey Date', 'Cycle 2 Number of Health Revisits', 'Cycle 2 Health Revisit Score', 'Cycle 2 Total Health Score', 'Cycle 3 Total Number of Health Deficiencies', 'Cycle 3 Number of Standard Health Deficiencies', 'Cycle 3 Number of Complaint Health Deficiencies', 'Cycle 3 Health Deficiency Score', 'Cycle 3 Standard Health Survey Date', 'Cycle 3 Number of Health Revisits', 'Cycle 3 Health Revisit Score', 'Cycle 3 Total Health Score', 'Total Weighted Health Survey Score', 'Number of Facility Reported Incidents', 'Number of Substantiated Complaints', 'Number of Fines', 'Total Amount of Fines in Dollars', 'Number of Payment Denials', 'Total Number of Penalties', 'Location', 'Processing Date']\n",
      "SAVING TO CSV\n",
      "SAVED TO CSV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#non_nurses = non_nurses.with_columns(pl.col([val for val in tot_nn]).cast(pl.i64).alias([val for val in tot_nn]))\\n\\nnon_labeled_facilities = non_nurses.group_by(\"PROVNUM\").agg(\\n    [\\n        pl.mean(tot_nn),\\n        pl.mean(emp_nn),\\n        pl.mean(ctr_nn),\\n    ]\\n)[tot_nn+emp_nn+ctr_nn]\\n\\nnon_nurses = non_nurses.with_columns(\\n    pl.col(\"Hrs_Admin\").cast(pl.Float64).alias(\"Hrs_Admin\")\\n)\\n\\nprint(\"SJSSJSJS\" *100)\\nprint(non_labeled_facilities.columns)\\nprint(non_labeled_facilities.dtypes)\\n.with_columns(\\n    total_work=pl.sum_horizontal(tot_nn),\\n    emp_work=pl.sum_horizontal(emp_nn),\\n    ctr_work=pl.sum_horizontal(ctr_nn)\\n).sort(\\n    \\'total_work\\', \\n    descending=True\\n))\\nprint(non_labeled_facilities)\\n\\nnon_labeled_facilities = non_labeled_facilities.with_columns(\\n    pl.when(pl.col(\"ctr_work\") >= pl.col(\"emp_work\")).then(pl.lit(\"Contractor\")).otherwise(pl.lit(\"Employer\")).alias(\"ML_Label\")\\n)\\n\\nprint(non_labeled_facilities)\\n\\nshow=False\\n\\n\\n\\n\\n# Example histogram\\nif show:\\n    sns.histplot(nurses[\"Hrs_RN\"], bins=100, kde=True, color=\"blue\", edgecolor=\"black\", linewidth=1.5)\\n    plt.xlabel(\"Registered Nurse % hours\")\\n    plt.title(\"Histogram of Registered Nurse % hours\")\\n    plt.show()\\n\\nworking_nurses = nurses.filter(pl.col(\"Hrs_RN\") > 0)\\nworking_nurses = working_nurses.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_RN\\').alias(\\'RNs\\')).sort(\\'WorkDate\\', descending=True)\\nfig = px.line(working_nurses.to_pandas(), x=\"WorkDate\", y=\"RNs\", title=\"Rn Hrs by Date\")\\nif show:\\n    fig.show()\\n\\n# I see a cycle, wow, weekends, they average 450k hrs during the weekend, but only 525 (75k more) during the week\\n# I also notice it is a little shorter just after new years\\n# Let\\'s compare them to non nurses, how about pharmasists\\n\\nworking_non_nurses = non_nurses.filter(pl.col(\"Hrs_Pharmacist\") > 0)\\nworking_non_nurses = working_non_nurses.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_Pharmacist\\').alias(\\'PMs\\')).sort(\\'WorkDate\\', descending=True)\\n\\nfig = px.line(working_non_nurses.to_pandas(), x=\"WorkDate\", y=\"PMs\", title=\"PM Hrs by Date\")\\nif show:\\n    fig.show()\\n\\n# so nurses work 525k to pharmacists 8k... and 450k to 1.5k\\n# physicians assistants must do more\\nworking_non_nurses = non_nurses.filter(pl.col(\"Hrs_PA\") > 0)\\nworking_non_nurses = working_non_nurses.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_PA\\').alias(\\'PAs\\')).sort(\\'WorkDate\\', descending=True)\\n\\nfig = px.line(working_non_nurses.to_pandas(), x=\"WorkDate\", y=\"PAs\", title=\"PA Hrs by Date\")\\nif show:\\n    fig.show()\\n\\n# or not...\\n# let\\'s compare registered nurses to those with director or admin roles\\n\\nrn = nurses.filter(pl.col(\"Hrs_RN\") > 0)\\nrn = rn.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_RN\\').alias(\\'RNs\\')).sort(\\'WorkDate\\', descending=True)\\n\\nrnd = nurses.filter(pl.col(\"Hrs_RNDON\") > 0)\\nrnd = rnd.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_RNDON\\').alias(\\'RNDirs\\')).sort(\\'WorkDate\\', descending=True)\\n\\nrna = nurses.filter(pl.col(\"Hrs_RNadmin\") > 0)\\nrna = rna.group_by(\"WorkDate\").agg(pl.mean(\\'Hrs_RNadmin\\').alias(\\'RNA\\')).sort(\\'WorkDate\\', descending=True)\\n\\nrnj = rn.join(rnd, on=\"WorkDate\", how=\"left\").join(rna, on=\"WorkDate\", how=\"left\")\\n\\nfig = px.line(rnj.to_pandas(), x=\"WorkDate\", y=[\"RNs\", \"RNDirs\", \"RNA\"], title=\"RN x RNDirs x RNA Hrs by Date\")\\nif show:\\n    fig.show()\\n\\n# make two sep collection of total hours, one for nurses one for non nurses\\n_nurse_workers = []\\n_non_nurse_workers = []\\nf=0# this flag flips when i stop seeing unique worker fields from nurses dataset\\nfor k,v in data_definitions.items():\\n    if f == 0:\\n        if \\'Hrs\\' in k and \\'emp\\' not in k and \\'ctr\\' not in k and \\'fn\\' not in k and \"DON\" not in k and \"admin\" not in k:\\n            _nurse_workers.append(k)\\n    else:\\n        if \\'Hrs\\' in k and \\'emp\\' not in k and \\'ctr\\' not in k and \\'fn\\' not in k:\\n            _non_nurse_workers.append(k)\\n    if \\'MedAide\\' in k:\\n        f=1\\n\\n# these seem to be null, check again, DEL\\n_non_nurse_workers.remove(\\'Hrs_Admin\\')\\n\\n# top_nurse_workers = nurses.group_by(\"PROVNAME\").agg(pl.sum(_nurse_workers)).sort(\\'PROVNAME\\', descending=True)\\n# print(top_nurse_workers)\\n\\n_nurses = nurses.group_by(\"WorkDate\").agg(pl.mean(_nurse_workers)).sort(\\'WorkDate\\', descending=True)\\n_non_nurses = non_nurses.group_by(\"WorkDate\").agg(pl.mean(_non_nurse_workers)).sort(\\'WorkDate\\', descending=True)\\n\\nfig = px.line(_nurses.to_pandas(), x=\"WorkDate\", y=_nurse_workers, title=\"Nurses\")\\nif show:\\n    fig.show()\\n\\nfig = px.line(_non_nurses.to_pandas(), x=\"WorkDate\", y=_non_nurse_workers, title=\"Non-Nurses\")\\nif show:\\n    fig.show()\\n\\n# For the set of all places, do places with more support staff have lower nurse working hours\\n# Quick test\\n# top ten places with the most nurse hours and non nurse hours\\ntop_10_n = nurses.group_by(\"PROVNAME\").agg(pl.mean(_nurse_workers)).with_columns(total_work=pl.sum_horizontal(_nurse_workers)).sort(\\'total_work\\', descending=True).head(10)#[\"PROVNAME\"])\\ntop_10_nn = non_nurses.group_by(\"PROVNAME\").agg(pl.mean(_non_nurse_workers)).with_columns(total_work=pl.sum_horizontal(_non_nurse_workers)).sort(\\'total_work\\', descending=True).head(10)#[\"PROVNAME\"])\\n\\ncommon = list(set(top_10_n) & set(top_10_nn))\\n\\n#_top_hours_nurses = nurses.group_by(\"PROVNUM\").agg(pl.sum(\\'Hrs_RN\\').alias(\\'Registered Nurses\\')).sort(\\'Registered Nurses\\', descending=True)\\n\\n#top_provnums = list(_top_hours_nurses[0:10][\"PROVNUM\"])\\n#top_prov = nurses.filter(pl.col(\"PROVNUM\").is_in(top_provnums))\\n#fig = px.box(top_prov, y=_top_hours_nurses, x=\"PROVNAME\", points=\"all\", notched=True, title=\"Box plot\")\\n#fig.show()\\n#_top_hours_non_nurses = non_nurses.group_by(\"PROVNUM\").agg(pl.sum(\\'Hrs_RN\\').alias(\\'Registered Nurses\\')).sort(\\'Registered Nurses\\', descending=True)\\n# There are lots and lots of insights in the data\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T22:35:24.386502Z",
     "start_time": "2025-04-15T22:35:20.801625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Machine Learning\n",
    "# Traveling Nurses, recc a place \n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#creating instance of one hot encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "base_dir = os.getcwd() + \"\\\\data\\\\\"\n",
    "provider_info = pl.read_csv(base_dir + \"output.csv\", separator=\"\\t\")\n",
    "provider_info = provider_info.drop_nulls(\"ML_Label\")\n",
    "pin = provider_info.with_columns(pl.col(\"ML_Label\").cast(pl.String).alias(\"ML_Label\"))\n",
    "\n",
    "potent=[\"Number of Certified Beds\", \"Number of Residents in Certified Beds\", \"Provider Resides in Hospital\", \"Continuing Care Retirement Community\", \"Special Focus Facility\", \"Most Recent Health Inspection More Than 2 Years Ago\", \"Provider Changed Ownership in Last 12 Months\", \"Overall Rating\", \"Health Inspection Rating\", \"QM Rating\", \"Staffing Rating\", \"RN Staffing Rating\", \"Reported CNA Staffing Hours per Resident per Day\", \"Reported LPN Staffing Hours per Resident per Day\", \"Reported RN Staffing Hours per Resident per Day\", \"Reported Licensed Staffing Hours per Resident per Day\", \"Reported Total Nurse Staffing Hours per Resident per Day\", \"Reported Physical Therapist Staffing Hours per Resident Per Day\", \"Expected CNA Staffing Hours per Resident per Day\", \"Expected LPN Staffing Hours per Resident per Day\", \"Expected RN Staffing Hours per Resident per Day\", \"Expected Total Nurse Staffing Hours per Resident per Day\", \"Adjusted CNA Staffing Hours per Resident per Day\", \"Adjusted LPN Staffing Hours per Resident per Day\", \"Adjusted RN Staffing Hours per Resident per Day\", \"Adjusted Total Nurse Staffing Hours per Resident per Day\", \"Total Weighted Health Survey Score\", \"Number of Facility Reported Incidents\", \"Number of Substantiated Complaints\", \"Number of Fines\", \"Number of Payment Denials\", \"Total Number of Penalties\", \"ML_Label\"]\n",
    "\n",
    "pin = pin[potent]\n",
    "\n",
    "\n",
    "pin = pin.with_columns(\n",
    "    pl.col(\"ML_Label\").cast(pl.Categorical).to_physical().alias(\"ML_Label_encoded\"),\n",
    ")\n",
    "pin = pin.drop(\"ML_Label\")\n",
    "\n",
    "for item in potent:\n",
    "    if item == \"ML_Label\":\n",
    "        pass\n",
    "    else:\n",
    "        if pin[item].dtype == pl.Boolean: \n",
    "            pin = pin.drop_nulls(item)\n",
    "        else:\n",
    "            pin = pin.drop_nulls(item)\n",
    "            val = pin[item].fill_nan(None).mean()\n",
    "            pin = pin.with_columns(pl.col(item).fill_nan(val))\n",
    "\n",
    "# I need to get the number of samples that are \"\" Contrator\n",
    "\n",
    "# get the same number of samples where they are employer at random\n",
    "\n"
   ],
   "id": "b16aa3281c2a5627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (12_217, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Number of ┆ Number of ┆ Provider  ┆ Continuin ┆ … ┆ Number of ┆ Number of ┆ Total     ┆ ML_Label │\n",
      "│ Certified ┆ Residents ┆ Resides   ┆ g Care    ┆   ┆ Fines     ┆ Payment   ┆ Number of ┆ ---      │\n",
      "│ Beds      ┆ in        ┆ in        ┆ Retiremen ┆   ┆ ---       ┆ Denials   ┆ Penalties ┆ str      │\n",
      "│ ---       ┆ Certifi…  ┆ Hospital  ┆ t Com…    ┆   ┆ i64       ┆ ---       ┆ ---       ┆          │\n",
      "│ i64       ┆ ---       ┆ ---       ┆ ---       ┆   ┆           ┆ i64       ┆ i64       ┆          │\n",
      "│           ┆ i64       ┆ bool      ┆ bool      ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 60        ┆ 47        ┆ false     ┆ false     ┆ … ┆ 1         ┆ 0         ┆ 1         ┆ Employer │\n",
      "│ 80        ┆ 45        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 60        ┆ 46        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 97        ┆ 88        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 30        ┆ 21        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 140       ┆ 63        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 72        ┆ 44        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 103       ┆ 65        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 120       ┆ 3         ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "│ 140       ┆ 61        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ Employer │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "shape: (12_217, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Number of ┆ Number of ┆ Provider  ┆ Continuin ┆ … ┆ Number of ┆ Number of ┆ Total     ┆ ML_Label │\n",
      "│ Certified ┆ Residents ┆ Resides   ┆ g Care    ┆   ┆ Fines     ┆ Payment   ┆ Number of ┆ _encoded │\n",
      "│ Beds      ┆ in        ┆ in        ┆ Retiremen ┆   ┆ ---       ┆ Denials   ┆ Penalties ┆ ---      │\n",
      "│ ---       ┆ Certifi…  ┆ Hospital  ┆ t Com…    ┆   ┆ i64       ┆ ---       ┆ ---       ┆ u32      │\n",
      "│ i64       ┆ ---       ┆ ---       ┆ ---       ┆   ┆           ┆ i64       ┆ i64       ┆          │\n",
      "│           ┆ i64       ┆ bool      ┆ bool      ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 60        ┆ 47        ┆ false     ┆ false     ┆ … ┆ 1         ┆ 0         ┆ 1         ┆ 0        │\n",
      "│ 80        ┆ 45        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 60        ┆ 46        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 97        ┆ 88        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 30        ┆ 21        ┆ false     ┆ true      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 140       ┆ 63        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 72        ┆ 44        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 103       ┆ 65        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 120       ┆ 3         ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "│ 140       ┆ 61        ┆ false     ┆ false     ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "12217\n",
      "11930\n",
      "shape: (11_930, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Number of ┆ Number of ┆ Provider  ┆ Continuin ┆ … ┆ Number of ┆ Number of ┆ Total     ┆ ML_Label │\n",
      "│ Certified ┆ Residents ┆ Resides   ┆ g Care    ┆   ┆ Fines     ┆ Payment   ┆ Number of ┆ _encoded │\n",
      "│ Beds      ┆ in        ┆ in        ┆ Retiremen ┆   ┆ ---       ┆ Denials   ┆ Penalties ┆ ---      │\n",
      "│ ---       ┆ Certifi…  ┆ Hospital  ┆ t Com…    ┆   ┆ f64       ┆ ---       ┆ ---       ┆ u32      │\n",
      "│ f64       ┆ ---       ┆ ---       ┆ ---       ┆   ┆           ┆ f64       ┆ f64       ┆          │\n",
      "│           ┆ f64       ┆ bool      ┆ bool      ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 60.0      ┆ 47.0      ┆ false     ┆ false     ┆ … ┆ 1.0       ┆ 0.0       ┆ 1.0       ┆ 0        │\n",
      "│ 80.0      ┆ 45.0      ┆ false     ┆ true      ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 60.0      ┆ 46.0      ┆ false     ┆ true      ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 97.0      ┆ 88.0      ┆ false     ┆ false     ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 30.0      ┆ 21.0      ┆ false     ┆ true      ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 35.0      ┆ 33.0      ┆ false     ┆ false     ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 60.0      ┆ 50.0      ┆ false     ┆ true      ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 140.0     ┆ 63.0      ┆ false     ┆ false     ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 72.0      ┆ 44.0      ┆ false     ┆ false     ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "│ 103.0     ┆ 65.0      ┆ false     ┆ false     ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "start pca\n",
      "[5.69542076e-01 4.06043585e-01 1.96851923e-02 3.24412624e-03\n",
      " 4.59780789e-04 3.77018344e-04 1.99153188e-04 1.15770495e-04\n",
      " 1.10954150e-04 8.08161872e-05]\n",
      "[[-2.04485408e-01  8.50619483e-01  5.94349273e-02 ...  2.77422929e-01\n",
      "  -5.99595995e-01  7.14438539e-01]\n",
      " [ 9.40842479e-01  5.15494385e-01  4.65646556e-01 ...  9.57032532e-01\n",
      "  -9.25824354e-01  1.49480637e-01]\n",
      " [ 5.99748472e-01  6.32665761e-01 -2.89460182e-02 ...  1.47176894e-02\n",
      "   3.99969769e-01  8.99656439e-04]\n",
      " ...\n",
      " [-2.53579014e-01 -2.29280275e-01  4.45081575e-01 ... -1.67994036e-01\n",
      "  -3.99275028e-01 -8.68011797e-01]\n",
      " [-7.62299140e-01 -6.72256912e-01 -1.94871273e+00 ... -2.22731880e+00\n",
      "  -1.63835127e+00  7.44388544e-02]\n",
      " [-8.45091483e-01 -6.16836329e-01  5.52300929e-01 ... -2.36436127e+00\n",
      "  -6.95044288e-01 -6.38944699e-01]]\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-15T22:56:47.366051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features and target variable\n",
    "X = pin.drop('ML_Label_encoded')\n",
    "y = pin['ML_Label_encoded']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  \n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=32)\n",
    "logistic_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_pca = logistic_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"Accuracy with PCA: {accuracy_pca}\")\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.pairplot(pin.to_pandas(), hue='ML_Label_encoded', vars=potent[:10])\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.countplot(pin.to_pandas()['ML_Label_encoded'], label = \"Count\")\n",
    "\n",
    "plt.figure(figsize=(30,20)) \n",
    "sns.heatmap(pin.corr(), annot=True)\n",
    "\n",
    "\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Breast Cancer Dataset')\n",
    "plt.colorbar(label='Diagnosis')\n",
    "plt.show()"
   ],
   "id": "1645c23ced61c705",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with PCA: 0.9882648784576697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
